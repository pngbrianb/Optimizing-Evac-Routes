{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Relevant Texts: NLP and Classification Modeling <br>\n",
    "_Authors: Amy Taylor and Veronica Giannota_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:** Since collecting all tweets that contain the phrase \"road closed\" will return a large set of useless tweets, a pre-filtering step was needed to separate the relevant tweets from useless tweets. Relevant tweets were defined as those with: (1) cross street information for a distinct location that could be located on a map and (2) a road that was FULLY blocked and inaccessible rather than partially inaccessible (i.e. some lanes closed). \n",
    "\n",
    "**Our strategy:** Build a classifier that can filter relevant tweets from useless tweets using natural language processing methods and a logistic regression classifier model. \n",
    "\n",
    "**Method**: \n",
    "<br> A corpus of 143 tweets (collected in Notebook #1) was downloaded and pre-labeled as either:\n",
    "- **0 = unrelated OR useless**  (EX. \"MVHS will remain closed tomorrow due to concerns about road conditions.\")\n",
    "\n",
    "- **1 = related, but road not FULLY blocked** (EX: \"Road construction. right lanes closed in #Pima on I-10 EB at Ruthrauff Rd\")  \n",
    "- **2 = relevant, road is fully blocked AND street info provided**\n",
    "\n",
    "Once labeled, the corpus was: \n",
    "1. split into training and testing data\n",
    "2. Word vectorized using sklearn CountVectorizer method\n",
    "3. Fit to a logistic regression model and scored based on the accuracy of the predicted class being 0, 1, or 2\n",
    "\n",
    "This notebook outlines these steps, analyzes the mislabeled tweets, and discusses the viability of the model altogether.\n",
    "\n",
    "### Sections\n",
    "  [1. Classification Modeling](#classification)\n",
    "<br>  [2. Missclassified Tweet Analysis](#analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Classification Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "   \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the dataframe containing the texts from 143 tweets as well as the pre-labeled `rating` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweed_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Road construction, left lane closed in #Albuqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Road construction. right lanes closed in #Pima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Road construction, shoulder closed in #ElPaso ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Ughhh at the dentist for a cleaning and the si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Road constructions. two right lanes closed in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweed_id  rating                                              tweet\n",
       "0         0       1  Road construction, left lane closed in #Albuqu...\n",
       "1         1       1  Road construction. right lanes closed in #Pima...\n",
       "2         2       1  Road construction, shoulder closed in #ElPaso ...\n",
       "3         3       0  Ughhh at the dentist for a cleaning and the si...\n",
       "4         4       1  Road constructions. two right lanes closed in ..."
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/twitter_corpus.csv\", sep='\\t', encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.1_ Determine the baseline model accuracy score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    58\n",
       "1    54\n",
       "0    31\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40559440559440557\n",
      "0.3776223776223776\n",
      "0.21678321678321677\n"
     ]
    }
   ],
   "source": [
    "print(58 / (58 + 54 + 31))\n",
    "print(54 / (58 + 54 + 31))\n",
    "print(31 / (58 + 54 + 31))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline score is ~40%, so any model we fit should perform better than 40%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id='classification'></a>\n",
    "**Step 1.2_ Train/test/split the data and CountVectorize**\n",
    "- For CountVectorize we will use all the default parameters with the exception of `analyzer = \"word\"` to separate every word and `ngram_range=(1, 2)` to supply bi-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tweet']\n",
    "y = df['rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.33)\n",
    "\n",
    "# instantiate countvectorizer\n",
    "vect = CountVectorizer(analyzer = \"word\", ngram_range=(1, 2))\n",
    "\n",
    "# fit on the training data, transform training and test data\n",
    "train_data = vect.fit_transform(X_train)\n",
    "test_data = vect.transform(X_test)\n",
    "train_data = train_data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 1831)\n",
      "(48, 1831)\n"
     ]
    }
   ],
   "source": [
    "# How many features did countvectorize create?\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Using these CountVectorize parameters, 1831 features were created from 143 tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.3_ Fit a Logistic Regression model to our vectorized data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8958333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amytaylor/anaconda3/envs/dsi/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/amytaylor/anaconda3/envs/dsi/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(train_data, y_train)\n",
    "print(lr.score(train_data, y_train))\n",
    "print(lr.score(test_data, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far this model performs with ~90% accuracy, meaning it can correctly predict all of the classes 90% of the time. However, this model is overfit to the training data. This could potentially be overcome if we provided a much larger dataset of tweets.\n",
    "\n",
    "Since we have three classes of tweets to distinguish, let's determine which classes the model is correctly and incorrectly predicting. We only really care if the model is correctly predicting class 2, or incorrectly predicting class 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analysis'></a>\n",
    "\n",
    "### Section 2. Misclassified Tweet Analysis: Examine which predictions are wrong\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.1_Generate predictions on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 0, 0, 2, 1, 2, 2, 1, 0, 2, 1, 1, 1, 0, 2, 2, 1, 2, 2, 1,\n",
       "       0, 2, 2, 2, 1, 1, 0, 1, 0, 0, 2, 2, 0, 2, 2, 0, 2, 1, 1, 2, 1, 0,\n",
       "       2, 0, 2, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = lr.predict(test_data)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1831)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.2_ Create a dataframe of the predictions from the test set**\n",
    "- Add columns for the `actual` classification, the `predicted` classication\n",
    "- Add a column for `new_score`, which will distinguish if the tweet was:\n",
    "    - correctly labeled\n",
    "    - incorrecly labeled (as class 0/1, class 1/2, or class 0/2)\n",
    "- The `new_score` = `actual` + (4 * `predicted` )\n",
    "- The summary of the combinations for the possible `new_score`s are given by the following table:\n",
    "   \n",
    "| -| Class 0 = usless tweet| Class 1 = related tweet| Class 2 = relevant tweet|\n",
    "|---|---|---|---|\n",
    "| **labeled as 0**| 0 = correct prediction|1 |2 |\n",
    "| **labeled as 1**| 4| 5 = correct prediction| 6|\n",
    "| **labeled as 2**| 8| 9|10 = correct prediction |\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_pred = pd.DataFrame(X_test, columns =['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Road closed. broken glass on roadway. in #Cora...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Road construction. two left lanes closed in #F...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Road construction, left lane closed in #Brevar...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ThereÕs no Wells Fargo Bank on Beatties Ford R...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>@FAIRImmigration @NBCNews @JuliaEAinsley You m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  actual  predicted  \\\n",
       "117  Road closed. broken glass on roadway. in #Cora...       2          2   \n",
       "19   Road construction. two left lanes closed in #F...       1          1   \n",
       "82   Road construction, left lane closed in #Brevar...       1          1   \n",
       "97   ThereÕs no Wells Fargo Bank on Beatties Ford R...       0          0   \n",
       "56   @FAIRImmigration @NBCNews @JuliaEAinsley You m...       0          0   \n",
       "\n",
       "     new_score  \n",
       "117         10  \n",
       "19           5  \n",
       "82           5  \n",
       "97           0  \n",
       "56           0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_pred.loc[:, 'actual'] = y_test\n",
    "wrong_pred.loc[:, 'predicted'] = pred\n",
    "wrong_pred.loc[:, 'new_score'] = wrong_pred['actual'] + (4* wrong_pred['predicted'])\n",
    "wrong_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different classes were predicted? (i.e. what is the number of `new_score`s generated)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  5,  0,  2,  6,  1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_pred['new_score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    20\n",
       "5     14\n",
       "0      9\n",
       "2      3\n",
       "6      1\n",
       "1      1\n",
       "Name: new_score, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_pred['new_score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Out of the nine possible `new_score`s, only five were generated. \n",
    "- Scores of 10, 5, and 0 are correct predictions\n",
    "- Incorrect predictions have the score of 2, 6, and 1\n",
    "    - Score = 2: Three **relevant** tweets incorrectly predicted as **useless**\n",
    "    - Score = 6: One **relevant** tweet incorrectly predicted as **related**\n",
    "    - Score = 1: One **related** tweet incorrectly predicted as **useless**\n",
    "\n",
    "> These results are beneficial to us, because no related or useless tweets are being incorrectly labeled as relevant. That is, our model is minimizing false postives at the expense of a few relevant tweets being incorrectly filtered out. \n",
    "\n",
    "> Ideally, our model will read in a set of unseen tweets, classify them as relevant or not, and only feed the relevant tweets into the next step (or notebook) that uses regex to extract the location from the Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.3_Isolate Misclassified Tweets**\n",
    "- Let's put these misclassified tweets into a dataframe so we can see where our model went wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>new_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>ROAD CLOSUREPark Road (Southbound lanes only) ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Cougar fans traveling to Lakeland for the Girl...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The drainage project on Center Street in #Vine...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Manchester road off Wayne avenue is closed off...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Southbound 101 freeway still closed at lost hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweet  actual  predicted  \\\n",
       "125  ROAD CLOSUREPark Road (Southbound lanes only) ...       2          1   \n",
       "51   Cougar fans traveling to Lakeland for the Girl...       2          0   \n",
       "10   The drainage project on Center Street in #Vine...       2          0   \n",
       "42   Manchester road off Wayne avenue is closed off...       2          0   \n",
       "40   Southbound 101 freeway still closed at lost hi...       1          0   \n",
       "\n",
       "     new_score  \n",
       "125          6  \n",
       "51           2  \n",
       "10           2  \n",
       "42           2  \n",
       "40           1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong = wrong_pred[(wrong_pred['new_score'] == 1) | \n",
    "                            (wrong_pred['new_score'] == 2) | (wrong_pred['new_score'] == 6)]\n",
    "\n",
    "wrong = wrong.sort_values(by='new_score', ascending=False)\n",
    "wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROAD CLOSUREPark Road (Southbound lanes only) between Selwyn Avenue and Tyvola Road are CLOSED and will re-opÉ https://t.co/TNZvF9lB8A\n",
      "--------\n",
      "Cougar fans traveling to Lakeland for the Girls NECC championship game. State Road 9 is closed in Wolcottville due to a structure fire, plan accordingly and find an alternative route. https://t.co/Be4mIPlhAM\n",
      "--------\n",
      "The drainage project on Center Street in #VineyardHaven continues this week - the road is closed to parking andÉ https://t.co/X04Uiougpu\n",
      "--------\n",
      "Manchester road off Wayne avenue is closed off by police. Giving traffic delivery updated as I see them\n",
      "--------\n",
      "Southbound 101 freeway still closed at lost hills. Agoura Road is jam southbound. Heading to the Civic arts Plaza fÉ https://t.co/tWzhAVh47x\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for i in wrong['tweet']:\n",
    "    print(i)\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Tweet| Actual Category | Missclassification Category| Score |\n",
    "|---| ---| ---| ---|\n",
    "|Cougar fans traveling to Lakeland for the Girls NECC championship game. State Road 9 is closed in Wolcottville due to a structure fire, plan accordingly and find an alternative route.| 2| 1  = related / not blocked | 6 |\n",
    "|ROAD CLOSUREPark Road (Southbound lanes only) between Selwyn Avenue and Tyvola Road are CLOSED and will re-opÉ | 2 | 0 = unrelated | 2 |\n",
    "|The drainage project on Center Street in #VineyardHaven continues this week - the road is closed to parking andÉ | 2 | 0 = unrelated | 2 |\n",
    "|Manchester road off Wayne avenue is closed off by police. Giving traffic delivery updated as I see them| 2 | 0 = unrelated | 2 |\n",
    "|Southbound 101 freeway still closed at lost hills. Agoura Road is jam southbound. Heading to the Civic arts Plaza fÉ | 1 | 0 = unrelated | 1|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
